{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fd3f866-7ab1-424e-9e28-a117f0be690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/toby/Documents/pdf-parser/backend/venv/lib64/python3.13/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1d6b958-936f-4f7c-805a-6cf238b29706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d17ba90-caa0-4a2e-b99c-7288a7458f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/toby/Documents/pdf-parser/backend/Sample Files/60118 NÁDUDVARI JOGHURT NATÚR 3_ 900G.pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/90327_HC ZSÍROLDÓ COMBI GRILL 1L 6DB#_2.pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/31255 KEDVENC ÍZEK FORRÓN FÜSTÖLT KÖTÖZÖTT COMB SONKA KB 1KG VCS (1).pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/14026 FRISS SERTÉS KARAJ CSN HUN.pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/32007 GYULAI KOLBÁSZ KB 2,5KG VG.pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/60055 MEDVE KÖRDOBOZOS SAJT SONKÁS 6 CIKKES 200G.pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/50180 - CIGÁNDI CÉRNAMETÉLT 4TOJ 5KG.pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/16011 FRISS CSIRKE MELLFILÉ VCS  IMP - ANIMEX.pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/24476_HEKK FILÉ BN 1000_800G 20_ G 1KG_10KG_#.pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/50037 - UNIVER ÉDES ANNA 200 GR6DB#.pdf\n",
      "/home/toby/Documents/pdf-parser/backend/Sample Files/22026 Kukta Gyorsfagyasztott panírozott csirkeszárny termékspecifikáció_aláírva.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/home/toby/Documents/pdf-parser/backend/Sample Files\"\n",
    "paths=[]\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    paths.append(file_path)\n",
    "for i in paths:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c6441ea-57ab-4b17-a723-91e1fb15efd7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Számlázási cím: 4445 Nagycserkesz-Halmosbokor 6.,Postacím: 4401 Nyíregyháza, Pf. 315., E-mail: hunchem@hunchem.hu  Weblap: ww.hungarochemicals.hu\n",
      "\n",
      "Combi Grill\n",
      "\n",
      "Specifikáció\n",
      "\n",
      "Külső:                                                       Világosbarna színű, jellemző szagú, tiszta folyadék.\n",
      "\n",
      "Sűrűség 20 0C-on:                                                                                           1,07 – 1,11 g/cm3\n",
      "\n",
      "1%-os oldat pH-értéke 250C-on:                                                                             11,7 – 12,1\n",
      "\n",
      "p-érték:                                                                                                                         6,2 – 6,8\n",
      "\n",
      "Szavatossági idő: 12 hónap\n",
      "\n",
      "2022.június\n",
      "\n",
      "HUNGARO CHEMICALS Kft.\n",
      "\n",
      "Központi telefonszám: +36-42-508-970\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = MarkItDown(enable_plugins=False) # Set to True to enable plugins\n",
    "result = md.convert(paths[1])\n",
    "print(result.text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c24f0098-ba9e-4680-8511-df439f46de79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      "Számlázási cím: 4445 Nagycserkesz-Halmosbokor 6.,Postacím: 4401 Nyíregyháza, Pf. 315., E-mail: hunchem@hunchem.hu  Weblap: ww.hungarochemicals.hu     \n",
      "                        \n",
      "HUNGARO CHEMICALS Kft. \n",
      "Központi telefonszám: +36-42-508-970 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Combi Grill \n",
      " \n",
      "Specifikáció \n",
      " \n",
      " \n",
      " \n",
      "Külső:                                                       Világosbarna színű, jellemző szagú, tiszta folyadék.  \n",
      " \n",
      "Sűrűség 20 0C-on:                                                                                           1,07 – 1,11 g/cm3 \n",
      " \n",
      "1%-os oldat pH-értéke 250C-on:                                                                             11,7 – 12,1 \n",
      " \n",
      "p-érték:                                                                                                                         6,2 – 6,8 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Szavatossági idő: 12 hónap \n",
      " \n",
      " \n",
      " \n",
      "2022.június \n",
      " \n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "import pymupdf  # assuming this works for you\n",
    "\n",
    "doc = pymupdf.open(paths[1])  # open the document\n",
    "pdf_text = \"\"  # initialize an empty string to hold all pages\n",
    "\n",
    "for page in doc:\n",
    "    text = page.get_text()  # get plain text (already a string)\n",
    "    pdf_text += text\n",
    "    pdf_text += \"\\f\"  # form feed as page delimiter\n",
    "\n",
    "print(pdf_text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94665dd4-6102-4d5e-b1f1-972366710acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/toby/Documents/pdf-parser/backend/Sample Files/60118 NÁDUDVARI JOGHURT NATÚR 3_ 900G.pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = paths[0] \n",
    "pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd311f87-333a-4131-aef9-9cc9fb3ea48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import pymupdf  # PyMuPDF\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "\n",
    "pdf_path = paths[0]  # PDF to parse\n",
    "preview_images = False\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Extract text\n",
    "# -------------------------------\n",
    "def extract_pdf_text(pdf_path):\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    pdf_text = \"\"\n",
    "    for page_index, page in enumerate(doc, start=1):\n",
    "        text = page.get_text()  # plain text\n",
    "        pdf_text += text + \"\\f\"  # page delimiter\n",
    "    return pdf_text\n",
    "\n",
    "def clean_text(raw_text):\n",
    "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', raw_text)  # collapse multiple newlines\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)           # normalize spaces\n",
    "    # text = text.replace('\\f', '\\n--- Page Break ---\\n')\n",
    "    return text.strip()\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text1(raw_text):\n",
    "    text = raw_text\n",
    "    \n",
    "    #Remove URLs/websites\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    #Collapse multiple newlines into double newline\n",
    "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)\n",
    "    \n",
    "    #Normalize spaces and tabs\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    \n",
    "    # Remove lines that are mostly non-alphanumeric (numbers, page numbers, etc.)\n",
    "    text = '\\n'.join([line for line in text.split('\\n') if re.search(r'[A-Za-zÁ-ÿ]', line)])\n",
    "    \n",
    "    #Remove very short lines (likely noise)\n",
    "    text = '\\n'.join([line for line in text.split('\\n') if len(line.strip()) > 5])\n",
    "    \n",
    "    #Strip leading/trailing whitespace\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "def clean_text3(raw_text):\n",
    "    HUNGARIAN_STOPWORDS = [\n",
    "    # Basic conjunctions and fillers\n",
    "    \"és\", \"vagy\", \"de\", \"hogy\", \"is\", \"az\", \"a\", \"azt\", \"ez\", \"egy\", \"minden\", \"valamint\",\n",
    "    \"illetve\", \"által\", \"általa\", \"általában\", \"kell\", \"számára\", \"általános\", \"volt\", \"van\",\n",
    "    \"továbbá\", \"mint\", \"mely\", \"melyek\", \"akkor\", \"amikor\", \"előtt\", \"után\", \"itt\", \"ott\",\n",
    "    \"ha\", \"lehet\", \"lenne\", \"úgy\", \"egyes\", \"néhány\", \"más\", \"kivéve\", \"bár\", \"pedig\", \"nos\",\n",
    "    \"tehát\", \"ezért\", \"azonban\", \"mindazonáltal\", \"sőt\", \"így\", \"úgy\", \"egyaránt\", \"vagyis\", \n",
    "    \"például\", \"stb\", \"pl\", \"ill\", \"azaz\",\n",
    "    \n",
    "    # Pronouns\n",
    "    \"én\", \"te\", \"ő\", \"mi\", \"ti\", \"ők\", \"magam\", \"magad\", \"maga\", \"magunk\", \"magatok\", \"maguk\",\n",
    "    \"ezek\", \"azok\", \"valaki\", \"valami\", \"semmi\", \"senki\", \"valamelyik\", \"valamennyi\",\n",
    "    \"egyik\", \"másik\", \"egyiksem\", \"másiksem\", \"mindenki\", \"mindenhol\", \"mindenféle\", \"akik\", \"amelyek\",\n",
    "    \n",
    "    # Temporal / spatial\n",
    "    \"ma\", \"most\", \"holnap\", \"régen\", \"tovább\", \"vissza\", \"előre\", \"alatt\", \"fölött\", \"között\", \"mellett\", \n",
    "    \"ellen\", \"felé\", \"iránt\", \"nélkül\", \"alapján\", \"kapcsán\", \"körül\", \"előtt\", \"után\", \"továbbra\", \"egyre\", \n",
    "    \"szinte\", \"újra\", \"ismét\",\n",
    "    \n",
    "    # Quantifiers / modifiers\n",
    "    \"sokan\", \"kevesen\", \"többen\", \"egyesek\", \"néhányan\", \"mindegyik\", \"együtt\", \"külön\", \"elég\",\n",
    "    \"nagyon\", \"kevésbé\", \"teljesen\", \"egészen\", \"alapvetően\", \"természetesen\", \"valójában\", \"egyáltalán\",\n",
    "    \n",
    "    # Negations / modal\n",
    "    \"nem\", \"se\", \"sem\", \"soha\", \"senki\", \"semmi\", \"egyáltalán\", \"lehet\", \"lenne\", \"kellene\", \"muszáj\"] \n",
    "    text = raw_text\n",
    "    \n",
    "    # 1. Normalize whitespace\n",
    "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)  # collapse multiple newlines\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)       # normalize spaces\n",
    "    \n",
    "    # 2. Remove OCR artifacts (page numbers, random punctuation, repeated company info)\n",
    "    text = re.sub(r'Oldal \\d+/\\d+', '', text)           # remove page numbers\n",
    "    text = re.sub(r'Verzi[ói] \\(datum\\).*', '', text)  # remove version/date lines\n",
    "    text = re.sub(r'Nadudvari Elelmiszer Kft\\.*', '', text)  # remove repeated company name\n",
    "    text = re.sub(r'EBIR csoport J[ée]ovahagyta.*', '', text)\n",
    "    text = re.sub(r'Linbert M[ée]rndki Tanacsad[óo] Iroda.*', '', text)\n",
    "    text = re.sub(r'[0-9]{5,}', '', text)  # remove long numeric strings (barcodes, IDs)\n",
    "    text = re.sub(r'[©®]', '', text)       # remove special symbols\n",
    "    \n",
    "    # 3. Remove extra punctuation\n",
    "    text = re.sub(r'[-–—]{2,}', '', text)  # remove multiple dashes\n",
    "    text = re.sub(r'[^\\S\\r\\n]{2,}', ' ', text)  # remove extra spaces\n",
    "    text = re.sub(r'[\\|\\[\\]\\(\\)]+', '', text)   # remove stray brackets/pipes\n",
    "    \n",
    "    # 4. Remove Hungarian stopwords (optional: only if you want to simplify text further)\n",
    "    pattern = r'\\b(?:' + '|'.join(HUNGARIAN_STOPWORDS) + r')\\b'\n",
    "    text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 5. Strip leading/trailing whitespace on each line\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    text = '\\n'.join(lines)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "pdf_text_raw = extract_pdf_text(pdf_path)\n",
    "pdf_text_clean = clean_text1(pdf_text_raw)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: Extract images and OCR text\n",
    "# -------------------------------\n",
    "def extract_images_with_ocr(pdf_path, preview=True):\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    images_info = []\n",
    "\n",
    "    for page_index, page in enumerate(doc, start=1):\n",
    "        imgs = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(imgs, start=1):\n",
    "            xref = img[0]\n",
    "            pix = doc.extract_image(xref)\n",
    "            image_bytes = pix[\"image\"]\n",
    "            image_ext = pix[\"ext\"]\n",
    "\n",
    "            # Load image in memory\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Preview image if desired\n",
    "            if preview:\n",
    "                image.show(title=f\"Page {page_index} - Image {img_index}\")\n",
    "\n",
    "            # Optional OCR\n",
    "            ocr_text = pytesseract.image_to_string(image)\n",
    "            images_info.append(clean_text3(ocr_text))\n",
    "            \n",
    "    return images_info\n",
    "\n",
    "images_data = extract_images_with_ocr(pdf_path, preview=preview_images)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3: Combine everything\n",
    "# -------------------------------\n",
    "pdf_data = {\n",
    "    \"text\": pdf_text_clean,\n",
    "    \"images\": images_data,\n",
    "}\n",
    "\n",
    "\n",
    "# # -------------------------------\n",
    "# # STEP 4: Preview output\n",
    "# # -------------------------------\n",
    "# print(\"==== PDF TEXT ====\")\n",
    "# print(pdf_data[\"text\"])  # preview first 1000 chars\n",
    "\n",
    "# print(\"\\n==== IMAGES & OCR ====\")\n",
    "# for img in pdf_data[\"images\"]:\n",
    "#     print(f\"{img['ocr_text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "23cf9ac2-613b-4d74-bb9c-cfdfe9b483ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dokumentun HACCP Dokumentum HACCP-1..1\\ntéma: elemzés kéd:\\nDokumentum — Termék-\\nnév: specifikacid\\nVerzid datum 12021.06.21.\\nTejiizeme\\nTERMEK SPECIFIKACIO\\n1. SZALLITO ADATAI\\n4181 Nadudvar, Gutenberg u. 1\\n2. TERMEK ADATOK\\nTermék megnevezése: Nadudvari natur joghurt 3,0% 900g.\\nTermék leirasa: Eldfldras, homogénezett termék. Zsirtartalom 3,0% m/m. Nettd témeg\\n900 g.\\n. ne 5 998 202 943 889\\nTermékazonositd:\\n3. OSSZETEVOK\\nPaszt6r6zott kultura.\\n4. JELOLESI AJANLAS\\nNatur joghurt,  6sszetevdk  jeldlés kételes.\\n5, FELHASZNALAS\\ntermék kézvetlen fogyasztasra alkalmas.\\n6. ADALEKANYAGOK\\n7. FIZIKAI-KEMIAI TULAJDONSAGOK\\nAllomany: — habart, surtin folyé, egynemti alvadék, kis mértékii felf6lézédés, enyhe savé\\nkivalas megengedett.\\nSzin egyenletesen csontfehér szint\\niz: kellemesen savanykas,  termék jellegének megfeleléen zamatos, telt, tiszta.\\nIllat: kellemesen savanykas,  termék jellegének megfeleléen aromas.\\nKészitette\\ndokumentacié  Linbert Mérndki Tanacsad6 Iroda szolgaltatasanak lermékeDokumentum HACCP\\ntéma: elemzés\\nDokumentum — Termck-\\nnév: specilikacid\\nTejiizeme\\n8. MIKROBIOLOGIAI HATARERTEKEK\\nDokumentum HACCP-I.1.1\\nkéd:\\nVerzid datum: 12021.06.21.\\nn e m M\\nSalmonella 10 0 0/252\\nS.aureus 5 2  10\\nPenészgomba 2 10? 5*10°\\nE.Coli 5  < <10\\nColiform 5 10 10?\\nE. faecalis 5 2 10? 10°\\nSzulf.red.clostridium 5 2 10 10?\\nEnterobacteriaceae 5 2 < 5\\n9. TAPLALKOZASI ERTEKEK\\nErték megnevezése Jellemzo érték Ertékek forrasa\\nEnergia KJ 223 KJ/100g Bevizsgalt\\nEnergia kcal 53 keal/100g Tapertekadarokbo!\\nZsirtartalom 3,0 g/100g energiatartalom.\\namelybol telitett zsirsavak 1,8 g/100g\\nSzénhidrat 2,8 g/100g\\namelyb6él cukrok 2,4 2/100¢g\\nFehérje 3,2 2/100g\\nNYo 0,10 g/100g\\n10. FOGYASZTHATOSAGI INFORMACIOK\\nLisztérzékenyek szamara Fogyaszthato  fogyaszthaté OJ\\nOvo-lakto vegetarianusok szamara Fogyaszthat6  fogyaszthaté L\\nVeyetarianusok szamara Fogyaszthaté L  fogyaszthaté\\n11. GENETIKAILAG MODOSITOTT ANYAGOK\\ntermék mentes genetikailag modositott 6sszetevOktdl?\\nKészitette: EBIR csoport Jévahagyta\\ndokumentaciéd  Linbert Méindéki ‘Tanacsadé roda szolgallatasanak lerméke\\nIgen  U1\\nUgyvezeté igazgatéDokumentum HACCP Dokumentum HACCP- 1.1.1\\ntema: elemzés kod:\\nDokumentum — Termék-\\nnév: specilikacidé\\nVerzié datum: 12021.06.21.\\nTejtizeme\\ngenetikai modositott jeldIni ? Igen O\\n12. ALLERGEN / INTOLERANCIA INFORMACIOK\\nGlutént tartalmaz6 gabonafélék  azokbol késziilt mentes tartalmaz L = eléfordulhat LJ\\ntermékek\\nRakfélék  azokbol késziilt termékek mentes tartalmaz L ~~ eléfordulhat\\nTojas  abbol késziilt termékek mentes tartalmaz 1 ~~ eléfordulhat 0\\nHal  abbol késziilt termékek mentes tartalmaz ~~ eléfordulhat OJ\\nFéldimogyord  abbol késziilt termékek mentes tartalmaz 1 eldéfordulhat 0\\nSzdjabab  abbdl késziilt termékek mentes tartalmaz 1 eléfordulhat O\\nTej  abbol késziilt termékek beleértve  laktdzt  mentesL tartalmaz eléfordulhat 1\\nCsonthéjasok  abbdl késziilt termékek mentes tartalmaz 1 ~~ eléfordulhat\\nZeller  abbol késziilt termékek mentes tartalmaz 1 ~— eléfordulhat 0\\nMustar  abbol késziilt termékek mentes tartalmaz 1 eléfordulhat C1\\nSzezammag  abbd késziilt termékek mentes tartalmaz lL ~elofordulhat\\nKén-dioxid   10 mg/kg,  !Omg/liter tsménységet mentes tartalmaz L ~— eléfordulhat O\\nmeghaladé SO2 —ben kifejezett szulfitok\\nCsillagfiirt  abbdl késziilt termékek mentes tartalmaz 1 = eléfordulhat\\nPuhatesttiek  abbdl késziilt termékek mentes tartalmaz ~~ eléfordulhat 0\\n13. ELTARTHATOSAG, TAROLAS ES SZALLITAS\\nTarolasi eldiras: — 0-6°C kézétt\\nFogyaszthatosagi idétartam zart, sértetlen csomagolasban: 36 nap\\nSzallitasi eléiras: 0-6°C kézott\\nSzallitas médja: fuvaroz6 alvallalkozo altal, disztribuciés raktarban tarolva  vevOh6z torténd\\ntarolas eldtt.\\n14. CSOMAGOLAS\\nTermék nett6 tsmege — egyedi csomagolas: 900 g\\nTermékek szama / gytijtécsomagolas: 6 db\\nEgyedi csomagolasu termékek szama raklaponként: 480 db\\nEgyedi csomagolas modja: PP védor  PP tet IML foéliaval\\nGylijtécsomagolas médja: Hullamkarton doboz\\nKészitette EBIR csoport Jévahagyta: Ugyvezeté igazgaté\\ndokumentacid  Linbert Mérnéki Tanacsadé Iroda szolgallatasdnak lermékeDokumentum HACCP Dokumentum HACCP-I.1.1\\ntéma: elemzés _ gfe kod:\\nDokumentum — Termeék-\\nnév: specifikacié\\nVerzié datum 12021.06.21.\\nTejiizeme\\nRaklap tipusa: EUR\\n15. JELOLES\\nLasd.: csomagolé anyag\\ntermék cimkéje\\nkévetkez6éket tartalmazza:\\n16. EGESZSEGUGYI ES BIZTONSAGI INFORMACIOK\\nTarsasagunknal HACCP élelmiszer-biztonsagi rendszer mtikédik, mindéségpolitikank   GMP  GHP\\nrendszerek garantaljak,\\ne Azellendérzétt alapanyagokat mindsitett beszallitoktol szerezziik be,\\ne Gyorstesztek alkalmazasaval  személyi higiéniat folyamatosan ellendrizziik,\\nAkésztermékeket rendszeresen akkreditalt laborvizsgalatoknak vetjiik ala,\\ne  élelmiszer-eldallitas soran eldforduld élelmezés-egészségiigyi kockazatokat kikiisz6béljiik,\\nminimalisra cs6kkentjiik  veszélyelemzés végrehajtasaval.\\ne  jogszabalyi eldirasok valtozasait nyomon kévetjiik.\\ne Rendszeres termékvisszahivasi probakat végziink,\\nBiztositjuk  élelmiszerek nyomonkévethetdéséget.\\n17. JOGSZABALYI MEGFELELES ES GARANCIA\\ntermék eldallitasa  hatdlyos EU eléirasoknak megfeleléen torténik.  termék specifikaciéban\\nszerepl6 informacidkat legjobb tudasunknak megfeleléen kézéltiik, tovabba kijelentjiik,\\nalapanyag beszallitéink altal rendelkezésre bocsatott informaciékon alapszanak.  felelés gyartdtd\\nelvarhaté  ésszerii elévigydzatossagi intézkedés megtértént, amit  bevezetett élelmiszer-\\nbiztonsagi rendszer garantal.\\nBizottsag EU 2023/915 rendelete 2023. aprilis 25.  élelmiszerekben eléforduld\\nszennyezé anyagok felsé hatarértékeirél   1881/2006/EK rendelet hatalyon kivill\\nhelyezésérél.\\n49/2014. IV. 29. VM rendelete  élelmiszerekben eldfordulé  szennyezOanyagokra\\ntermészetes eredetii artalmas anyagokra vonatkozé hatarértékekrél,   élelmiszerekkel\\nrendeltetésszertien érintkezésbe keriilé  anyagokkal, targyakkal kapcsolatos kévetelményekré\\n4/1998. XI. 11. EtiM rendelet  élelmiszerekben elé6forduld mikrobiolégiat szennyezddések\\nmegengedheté mértékérdl.\\nBizottsag 2073/2005/EK rendelete  élelmiszerek mikrobiologiai kritériumairél\\nKészitette\\ndokumentacié  Linbert Mérndki Tanacsado roda szolgaltalasanak teimékeAdudv\\n1 Nady\\nAdése’Dokumentum HACCP Dokumentum HACCP-1.1.1\\ntéma: elemzés kod:\\nDokumentum _ Termék-\\nnév: specifikacio\\nVerzio datum: 12021.06.21.\\nTeiiizeme\\n18. TITOKTARTAS\\nEzen termékspecifikacio   benne k6zélt informacidk  tulajdonat képezik.\\nEzeket harmadik félnek tovabbadni  elézetes irasbeli engedélye nélkiil\\nszigoruan tilos.\\nKESZITETTE ELLENORIZTE\\nInform./szervezet\\nNév: Kapus David\\nMunkakér: EBIR-vezetd\\nDatum:\\nAlairas:\\naug in st\\nm:\\nCgj.: 09-09-003 140\\nBanksz.:\\n{4\\nKészitette\\ndokumentacio  Linberl Mérnéki Tanacsad6 Iroda szolgaltatasanak termékeHarapké Tamas\\nTermékfejleszté technologus\\n2025.05.12.honk Soares'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(pdf_data[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4eac3a9-4ba9-4a58-a49e-09b641a3f5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6710"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"\".join(pdf_data[\"images\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9546ee5-1207-4d2f-87d3-2796e777b624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4249"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5810b769-dcc6-49af-a648-b4f8f7115afc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytesseract'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytesseract\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pytesseract'"
     ]
    }
   ],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0144b8c7-4399-4598-871e-c0e1082df23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in ./venv/lib64/python3.13/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in ./venv/lib64/python3.13/site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in ./venv/lib64/python3.13/site-packages (from pytesseract) (12.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "764a6b7d-4241-4e27-bc28-0e7cc608c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google-genai\n",
      "  Downloading google_genai-1.45.0-py3-none-any.whl.metadata (45 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /home/toby/.local/lib/python3.13/site-packages (from google-genai) (4.10.0)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-genai)\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /home/toby/.local/lib/python3.13/site-packages (from google-genai) (0.28.1)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from google-genai)\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/lib/python3.13/site-packages (from google-genai) (2.32.4)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/lib/python3.13/site-packages (from google-genai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3.13/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/toby/.local/lib/python3.13/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: certifi in /home/toby/.local/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/toby/.local/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/toby/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->google-genai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3.0.0,>=2.0.0->google-genai)\n",
      "  Using cached pydantic_core-2.41.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.11.0 (from google-genai)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.0.0->google-genai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.3.0)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading google_genai-1.45.0-py3-none-any.whl (238 kB)\n",
      "Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Using cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Using cached pydantic_core-2.41.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: websockets, typing-extensions, tenacity, pyasn1, cachetools, annotated-types, typing-inspection, rsa, pydantic-core, pyasn1-modules, pydantic, google-auth, google-genai\n",
      "Successfully installed annotated-types-0.7.0 cachetools-6.2.1 google-auth-2.41.1 google-genai-1.45.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.3 pydantic-core-2.41.4 rsa-4.9.1 tenacity-9.1.2 typing-extensions-4.15.0 typing-inspection-0.4.2 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52b5b8-47c7-4dd3-b2cf-685b9bb65866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store API key in a string\n",
    "api_key = \"YAIzaSyBfNT7Asw_5NTpd_-d3Auu-l1BCh0Y6iA0\"\n",
    "\n",
    "# Use it to initialize the client\n",
    "from google import genai\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# Now you can call the API\n",
    "prompt = \"Summarize this document\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[prompt]\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e9ca90-c34a-4e80-acb0-af78b4f9f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6040c9b3-4782-4fed-8560-e442f6bfa81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"allergens\": {\n",
      "    \"Gluten\": 0,\n",
      "    \"Egg\": 0,\n",
      "    \"Crustaceans\": 0,\n",
      "    \"Fish\": 0,\n",
      "    \"Peanut\": 0,\n",
      "    \"Soy\": 0,\n",
      "    \"Milk\": 1,\n",
      "    \"Tree nuts\": 0,\n",
      "    \"Celery\": 0,\n",
      "    \"Mustard\": 0\n",
      "  },\n",
      "  \"nutritional_values_per_100g\": {\n",
      "    \"Energy_KJ\": 223,\n",
      "    \"Energy_kcal\": 53,\n",
      "    \"Fat\": 3.0,\n",
      "    \"Carbohydrate\": 2.8,\n",
      "    \"Sugar\": 2.4,\n",
      "    \"Protein\": 3.2,\n",
      "    \"Sodium\": 0.04\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import pathlib\n",
    "\n",
    "api_key = \"AIzaSyBfNT7Asw_5NTpd_-d3Auu-l1BCh0Y6iA0\"\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# Retrieve and encode the PDF byte\n",
    "filepath = pathlib.Path(paths[0])\n",
    "\n",
    "prompt = '''Analyze the pdf. Return JSON of\n",
    "- If it contains allergens Gluten, Egg, Crustaceans, Fish, Peanut, Soy, Milk, Tree nuts, Celery, Mustard. (return 0 or 1)\n",
    "- Nutritional values: Energy, Fat, Carbohydrate, Sugar, Protein, Sodium\n",
    "'''\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.5-flash\",\n",
    "  contents=[\n",
    "      types.Part.from_bytes(\n",
    "        data=filepath.read_bytes(),\n",
    "        mime_type='application/pdf',\n",
    "      ),\n",
    "      prompt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e35b5c7-dad1-4f89-838a-4ea91ba04cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"```json\n",
      "{\n",
      "  \"allergens\": {\n",
      "    \"Gluten\": 0,\n",
      "    \"Egg\": 0,\n",
      "    \"Crustaceans\": 0,\n",
      "    \"Fish\": 0,\n",
      "    \"Peanut\": 0,\n",
      "    \"Soy\": 0,\n",
      "    \"Milk\": 1,\n",
      "    \"Tree nuts\": 0,\n",
      "    \"Celery\": 0,\n",
      "    \"Mustard\": 0\n",
      "  },\n",
      "  \"nutritional_values_per_100g\": {\n",
      "    \"Energy_KJ\": 223,\n",
      "    \"Energy_kcal\": 53,\n",
      "    \"Fat\": 3.0,\n",
      "    \"Carbohydrate\": 2.8,\n",
      "    \"Sugar\": 2.4,\n",
      "    \"Protein\": 3.2,\n",
      "    \"Sodium\": 0.04\n",
      "  }\n",
      "}\n",
      "```\"\"\"\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='jL3yaP2lCNr7xN8PhM6HKQ' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=198,\n",
      "  prompt_token_count=1353,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=63\n",
      "    ),\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.DOCUMENT: 'DOCUMENT'>,\n",
      "      token_count=1290\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=1272,\n",
      "  total_token_count=2823\n",
      ") automatic_function_calling_history=[] parsed=None\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7bc25-e4bd-45a9-8f14-ceaef02fd72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f724322e-6e52-4475-a7d5-9f73b1c4edad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytesseract'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpymupdf\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytesseract\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# CONFIGURATION\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     14\u001b[39m pdf_path = paths[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# PDF to parse\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pytesseract'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import pymupdf  # PyMuPDF\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------\n",
    "pdf_path = paths[0]  # PDF to parse\n",
    "preview_images = True\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Extract text\n",
    "# -------------------------------\n",
    "def extract_pdf_text(pdf_path):\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    pdf_text = \"\"\n",
    "    for page_index, page in enumerate(doc, start=1):\n",
    "        text = page.get_text()  # plain text\n",
    "        pdf_text += text + \"\\f\"  # page delimiter\n",
    "    return pdf_text\n",
    "\n",
    "def clean_text(raw_text):\n",
    "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', raw_text)  # collapse multiple newlines\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)           # normalize spaces\n",
    "    text = text.replace('\\f', '\\n--- Page Break ---\\n')\n",
    "    return text.strip()\n",
    "\n",
    "pdf_text_raw = extract_pdf_text(pdf_path)\n",
    "pdf_text_clean = clean_text(pdf_text_raw)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: Extract images and OCR text\n",
    "# -------------------------------\n",
    "def extract_images_with_ocr(pdf_path, preview=True):\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    images_info = []\n",
    "\n",
    "    for page_index, page in enumerate(doc, start=1):\n",
    "        imgs = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(imgs, start=1):\n",
    "            xref = img[0]\n",
    "            pix = doc.extract_image(xref)\n",
    "            image_bytes = pix[\"image\"]\n",
    "            image_ext = pix[\"ext\"]\n",
    "\n",
    "            # Load image in memory\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Preview image if desired\n",
    "            if preview:\n",
    "                image.show(title=f\"Page {page_index} - Image {img_index}\")\n",
    "\n",
    "            # Optional OCR\n",
    "            ocr_text = pytesseract.image_to_string(image)\n",
    "\n",
    "            images_info.append({\n",
    "                \"page\": page_index,\n",
    "                \"image_index\": img_index,\n",
    "                \"format\": image_ext,\n",
    "                \"ocr_text\": ocr_text,\n",
    "            })\n",
    "    return images_info\n",
    "\n",
    "images_data = extract_images_with_ocr(pdf_path, preview=preview_images)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3: Combine everything\n",
    "# -------------------------------\n",
    "pdf_data = {\n",
    "    \"text\": pdf_text_clean,\n",
    "    \"images\": images_data,\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 4: Preview output\n",
    "# -------------------------------\n",
    "print(\"==== PDF TEXT ====\")\n",
    "print(pdf_data[\"text\"])  # preview first 1000 chars\n",
    "\n",
    "print(\"\\n==== IMAGES & OCR ====\")\n",
    "for img in pdf_data[\"images\"]:\n",
    "    print(f\"Page {img['page']}, Image {img['image_index']}, Format {img['format']}\")\n",
    "    print(f\"OCR text (first all chars): {img['ocr_text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1a66e-f562-488f-8f2c-19e671a1bb68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
